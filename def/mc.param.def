/* -*- mode: c -*- */


param<  MONOLITHIC_PRF, monolithic_prf, bool, false>
param<  MONOLITHIC_PRF_ENTRIES, monolithic_prf_entries, uns, 512>
param<  MAX_PRF_PER_SLOT, max_prf_per_slot, uns, 32>
     // this should be at least as big as 64 / num_fus_per_cluster

param<  ISCA03_CONFIG, isca03_config, bool, false>
param<  COPY_OPS_USE_ISSUE_PORTS, copy_ops_use_issue_ports, bool, false>
param<  COPY_OPS_USE_ISSUE_SLOTS, copy_ops_use_issue_slots, bool, false>
param<  COPY_OPS_USE_SCHED_CYCLE, copy_ops_use_sched_cycle, bool, false>
param<  COPY_OPS_FOR_ALL_GLOBAL, copy_ops_for_all_global, bool, false>
param<  PART_MODEL, part_model, bool, false>
     // like parcerisa et al. 
param<  COPY_OPS_USE_VALID_MASK, copy_ops_use_valid_mask, bool, false>
     // indicate which non-local clusters already have result.  
param<  ALL_OPS_GLOBAL_BROADCAST, all_ops_global_broadcast, bool, false>
     // baseline (no copy ops needed)
param<  BROADCAST_TO_MASK_ONLY, broadcast_to_mask_only, bool, true>
     // if 0: no skipping clusters during broadcast.  

param<  COPY_OP_DELAY, copy_op_delay, uns, 1>

param<  DCOUNT_THRESHOLD, dcount_threshold, uns, 64>
param<  STEER_MODULO_AMT, steer_modulo_amt, uns, 16>
param<  STEER_MODULO_DIV, steer_modulo_div, uns, 4>
     // desired cluster = (op->op_num % steer_modulo_amt) / steer_modulo_div
param<  STEER_MODULO_PC, steer_modulo_pc, bool, false>
     // if true, steer based on instruction address rather than op_num.

param<  BYPASS_CONNECTIVITY, bypass_connectivity, uns, 3>
     // full: # clusters - 1.  minimum: 1.
param<  NUM_NODE_BLOCK_WRITE_PORTS, num_node_block_write_ports, uns, 0>
     // if set: limit the number of write ports to each node block.  affects steering.

param<  USE_BROADCAST_BUFFERS, use_broadcast_buffers, bool, false>
param<  NUM_BB_WRITE_PORTS, num_bb_write_ports, uns, 32>
param<  NUM_BROADCAST_BUFFER_ENTRIES, num_broadcast_buffer_entries, uns, 128>
param<  BROADCAST_TO_ALL, broadcast_to_all, bool, false>
     // broadcast_to_all: if 0, only broadcast to specified cluster.  if 1, broadcast
     // to every cluster between source and destination clusters as well.  

param<  NUM_RAS_ENTRIES, num_ras_entries, uns, 8>


param<  BYPASS_MUX_DELAY, bypass_mux_delay, uns, 0>
     // can delay stage_receive_cycle[stage] when this field is set.  

param<  STEERING_FAILURE_THRESHOLD, steering_failure_threshold, uns, 100>
     // for steering algorithm: if a stage is full more than n times when trying
     // to place a group, then just stall the checkpoint.

     // begin steering parameters
param<  NUM_CLT_WRITE_PORTS, num_clt_write_ports, uns, 0>
param<  USE_SPOUSE_CONFIDENCE, use_spouse_confidence, bool, false>
param<  USE_BRANCH_FUTURE, use_branch_future, bool, false>
param<  BRANCH_FUTURE_LENGTH, branch_future_length, uns, 3>
param<  NUM_SPOUSES_FOR_SCOPE, num_spouses_for_scope, uns, 2>
     // should not be more than 2.  
param<  STEERING_ALGORITHM, steering_algorithm, uns, 0>
     // 0: do steer_to_lao_nearest_neighbor
     // non-zero: do steer_micro35_lao
     // 2 (bit 1): determine live  (micro35_steer_determine_live)
     // 4 (bit 2): determine done  (micro35_steer_determine_done)
     // the two above require more than just a mapper.  must be updated at write/retire time.  
     // 8 (bit 3): favor_same_cluster (micro35_steer_favor_same_cluster)
     // 16 (bit 4): stall upon full stage queue (micro35_steer_stall_for_full_stage)
     // 32 (bit 5): if desired slot full, try to pick another good slot
     //             (micro35_steer_main_full_pick_alternate);
     // 64 (bit 6): try a second source (micro35_steer_try_second_source)
     // 128 (bit 7): try a spouse.  (micro35_steer_try_spouse)
     // 256 prioritize based on oldest instruction, not lao (micro35_steer_to_oldest)

param<  NUM_DEPENDENTS_PER_STAGE, num_dependents_per_stage, uns, 2>
     // for steering algorithm.  ideally, how many dependents should be placed per stage.
     // end steering parameters

param<  PERFECT_BUS_DENY_HANDLING, perfect_bus_deny_handling, bool, true>
     // ignore bus contention.  
     

param< CLT_PREDICTION_ALGORITHM, clt_prediction_algorithm, uns, 0>
     // if 0, do close to perfect.
     // 1: completely pessimistic: predict everything broadcasts the whole way
     // 2: completely optimistic: predict nothing broadcasts
     // 4: good prediction.  use spouses (must set bit 16.)
     // 8: not really prediction, but after reading clt/cam, do we change pessimistic to exact?
     // 16: keep track of where older spouses are.  
     
param<  VARIABLE_CLUSTER_DELAY, variable_cluster_delay, bool, false>
param<  USE_BUS_CYCLES, use_bus_cycles, bool, false>
     // flag to use old scheduling code, not stage_receive_cycle

param<  FUS_PER_BUS_STAGE, fus_per_bus_stage, uns, 2>
     // number of fus per stage of each global bus.  
param<  BUS_ARB_BUFFER_DEPTH, bus_arb_buffer_depth, uns, 8>
     // number of cycles worth of instructions buffered, arbitrating for global bus.
param<  CLT_READ_LATENCY, clt_read_latency, uns, 3>
     // number of cycles from select to read the clt.  should be <= bus_arb_buffer_depth.  


param<  MICRO35_CONFIG, micro35_config, bool, false>
param<  MICRO35_GLOBAL_BUS, micro35_global_bus, bool, false>
 
param<  RESULT_WRAP_AROUND_DELAY, result_wrap_around_delay, uns8, 0>

param<  NUM_FAST_RESULT_SLOTS, num_fast_result_slots, uns8, 1>

param<  USE_NEIGHBOR_BROADCAST, use_neighbor_broadcast, bool, false>
param<  RESULT_STORAGE_JUMP, result_storage_jump, uns, 0>
     // r_s_j is 0 for clusters, 1 for nearest neighbor fast bypass, etc.

param<  COLLECT_DEPENDENCY_STATS, collect_dependency_stats, bool, false>

param<  USE_PRESCHEDULER, use_prescheduler, bool, false>
param<  PRESCHEDULE_STAGES, preschedule_stages, uns, 1>

param<  MAX_LAO_COUNTER, max_lao_counter, uns, 3>
param<  LAO_COUNTER_THRESHOLD, lao_counter_threshold, uns, 2>

param<  SCHEDULER_ARBITRATES_BUS, scheduler_arbitrates_bus, bool, false>


param<  CONVERT_STORE, convert_store, uns, 0>
param<  CONVERT_ONLY_IF_RB_SRC_TC_DEST, convert_only_if_rb_src_tc_dest, bool, false>

param<  EXTRA_STORE_LATENCY, extra_store_latency, uns, 0>

param<  EQUAL_LIMITED, equal_limited, uns, 0>
     // no extra limits for rb->tc (byp-3 is used for tc alus only.) 

param<  TC_CONVERSION, tc_conversion, uns, 0>
     // when reg file stores data in rb format, add extra latency to tc ops.

param<  OPTIMIZE_BYTE, optimize_byte, bool, false>
     // one of the sources can be in rb format.  

param<  STEER_MOVES, steer_moves, bool, false>
     // moves can be rb or tc, depending on what the parent is.

param<  RANDOMIZE_LATENCY, randomize_latency, bool, false>
     // changes 2-cycle ops to 1, 2, or 3-cycle ops.

param<  ONLY_RB_LIMITED_BYPASS, only_rb_limited_bypass, bool, false>
     // only rb-dest ops have limited bypass.  

param<  ONLY_TC_LIMITED_BYPASS, only_tc_limited_bypass, bool, false>
     // only tc-src ops have limited bypass. 

param<  BYPASS_PREDICTOR_THRESHOLD_TOP, bypass_predictor_threshold_top, uns, 0>
     /* if non-zero, use the predictor to determine if an op w/ 2 sources gets its
	operands off the bypass network less than <this many> cycles apart. */
param<  BYPASS_PREDICTOR_THRESHOLD_BOTTOM, bypass_predictor_threshold_bottom, uns, 0>

param<  LOADS_BYPASS_TO_ALL_CLUSTERS, loads_bypass_to_all_clusters, bool, false>
     /* this parameter overrides only_bypass_within_cluster.  assumes num_load_store_per_packet leftmost
      functional units have all bypass paths indicated by bypass_mask.  */

param<  ONLY_BYPASS_WITHIN_CLUSTER, only_bypass_within_cluster, bool, false>
     /* use with flex_byass. other units must wait to get result from reg file. */

param<  FLEX_BYPASS, flex_bypass, bool, false>

param<  INTERNAL_BYPASS_MASK, internal_bypass_mask, uns64, 0xffffffffffffffffull>
param<  EXTERNAL_BYPASS_MASK, external_bypass_mask, uns64, 0xffffffffffffffffull>
     /* which levels of bypass are available to all other functional units; same for all functional units. */

param<  EXTRA_BACKEND_RECOVERY_CYCLES, extra_backend_recovery_cycles, uns, 0>

param<  BYPASS_1_N, bypass_1_n, uns, false>
     // for hpca2001 / rb_wake: only broadcast 1st cycle after exe, or 4 or more cycles after exe
param<  ONLY_ONE_BYPASS, only_one_bypass, bool, false>
     // for hpca2001, only set rb cannot receive tc except from reg file

param<  HPCA2001_RB, hpca2001_rb, bool, false>

param<  PERFECT_RB_PREDICTION, perfect_rb_prediction, bool, true>

param<  QUAD_TO_LONG_PENALTY, quad_to_long_penalty, uns, 2>
     // replay if forwarding from quad to long in rb format.  
     // typically time to progress to scoreboard

param<  SCADD_PENALTY, scadd_penalty, uns, 2>
     // time to determine source is out of range.  maybe rfile + tc exec latency - 1

param<  COLLECT_OP_TYPE_STATS, collect_op_type_stats, bool, false>

param<  NUM_RB_OPS_PER_PACKET, num_rb_ops_per_packet, uns, 0>
param<  NUM_NON_RB_OPS_PER_PACKET, num_non_rb_ops_per_packet, uns, 0>


param<  DISABLE_AVAIL_ADJUSTMENT, disable_avail_adjustment, int, 0>

param<  VARIABLE_SCHED_LATENCY, variable_sched_latency, bool, true>
     // gets reset to false for perfect, 2-stage, or 3-stage scheduling.

param<  NUM_FAST_SCHED_OPS_PER_PACKET, num_fast_sched_ops_per_packet, uns, 0>

param<  EXTRA_CYCLE_COLLISION_VICTIM, extra_cycle_collision_victin, uns, 0>

param<  NUM_SLOW_SCHED_OPS_PER_PACKET, num_slow_sched_ops_per_packet, uns, 0>

param<  MC_DONT_EXEC_NOP, mc_dont_exec_nop, bool, false>

param<  NUM_NODE_BLOCKS, num_node_blocks, uns, 0>
// for semi-unified scheduling.  0: defaults to node_width.  

param<  PRIORITY_REVERSE_CYCLES, priority_reverse_cycles, uns, 1>

param<  YOUNGEST_FIRST_AFTER_COLLISION, youngest_first_after_collision, bool, false>

param<  NUM_PRIORITY_STAGES, num_priority_stages, uns, 1>

param<  EXTRA_PRE_SCHED_PIPE, extra_pre_sched_pipe, uns, 0>

/* 1: all data addressess associated w/ previous isolated miss will hit 
   2: if static load has had an isolated miss, this instance will hit */
param<  ISO_MISS_REPL_UPPER, iso_miss_repl_upper, bool, false>
param<  ISO_MISS, iso_miss, bool, false>

/* the number of cycles, on either side of a miss, that determine if it is "isolated" */
param<  ISO_MISS_THRESH, iso_miss_thresh, uns, 20>

param<  LOGIC_TREE_CYCLES, logic_tree_cycles, uns, 0>
param<  EXTRA_ADDR_DECODE, extra_addr_decode, uns, 0>
param<  HIGH_FREQ_CORE, high_freq_core, uns, 0>

param<  UNUSED_FUS, unused_fus, uns, 0>
/* bit vector indicating which func units are not used. */
param<  RB_CLUSTER, rb_cluster, uns, 0>
/* bit vector indicating which clusters use redundant-binary arithmetic.  should be last clusters */
param<  RB_CONVERSION, rb_conversion, uns, 2>
     /* num cycles to convert from rb to 2's comp */
param<  NON_RB_EXTRA_LATENCY, non_rb_extra_latency, uns, 0>
     /* extra time for non-rb addition */
param<  RB_EXEC_ON_NON_RB, rb_exec_on_non_rb, uns, 0>
param<  COLLECT_RB_STATS, collect_rb_stats, uns, 0>

/* cluster parameters */
param<  FU_CLUSTER_DELAY, fu_cluster_delay, uns, 1>
param<  WAKEUP_DELAY, wakeup_delay, uns, 0>
param<  NUM_CLUSTERS, num_clusters, uns, 1>

/* 0: alternate left/right alignment.
   1: left alignment
   2: round-robin alignment for universal fus only.
 */
param<  CHECKPOINT_ALIGNMENT, checkpoint_alignment, uns, 0>

/* if non-zero, this indicates the max number of non-scheduled ops per slot */
param<  MAX_NOT_DONE_PER_SLOT, max_not_done_per_slot, uns, 0>

/* block-style checkpoint parameters */
param<  BLOCK_CHKPT, block_chkpt, uns, 0>  /*enable block-style checkpoints */
param<  SLOTS_PER_CHKPT, slots_per_chkpt, uns, 1>
param<  ROWS_PER_CHKPT, rows_per_chkpt, uns, 1>
     /* if block_chkpt is non-zero, that many issue slots will be used for one checkpoint.
	rows_per_chkpt * slots_per_chkpt = #insts in checkpoint */


/* the following options should be used for the mobile checkpoints model only. 
 * set only 1 of pipelined_schedule, base_1_stage_schedule, base_2_stage_schedule.
 * only set dont_rewake or hybrid_select if pipelined_schedule is set. 
 */

     /* assert this for complexity-effective or hybrid of this & conventional window. */
param<  HYBRID_ISSUE, hybrid_issue, uns, 0>

     /* number of total node tables that act as fifos.  set to node_width for complexity-effective. */
param<  NUM_FIFOS, num_fifos, uns, 0>

     /* for old implementation of wisconsin scheduling. */
param<  WISCONSIN, wisconsin, bool, false>

/* 2: binary inter-cluster switch */
param<  STEER_TO_PARENTS, steer_to_parents, uns, 0>

/* 1 cycle for wakeup , 1 cycle for select */
param<  PIPELINED_SCHEDULE, pipelined_schedule, uns, 0>

/* if 0: instructions in map stage can become awake, and must only be selected (not wakened) in node stage */
param<  RAT_TIME, rat_time, uns, 0>

/* don't make instructions backoff if not really ready */
param<  DONT_REWAKE, dont_rewake, uns, 0>

/* if not really ready , give lower priority rather than backing off */
param<  HYBRID_SELECT, hybrid_select, uns, 0>

/*base model.  fsm used for comparing against pipelined schedule */
param<  BASE_1_STAGE_SCHEDULE, base_1_stage_schedule, uns, 0>    /*base model */

/*base model.  fsm used for comparing against pipelined schedule */
param<  BASE_2_STAGE_SCHEDULE, base_2_stage_schedule, uns, 0>    /*base model */

/*base model. keep instructions at low priority.  set hybrid_select */
param<  LOW_PRIORITY_TOGGLE, low_priority_toggle, uns, 0>    /*base model */

/* use only w/ base_1_stage_schedule */
param<  DUPLICATE_MAP, duplicate_map, uns, 0>

/*base model. prioritize based on ready parents previous cycle.  set pipelined_schedule */
param<  PRIORITIZE_REALLY_READY, prioritize_really_ready, uns, 0>    /*base model */

/*base model.  deassert: instructions don't sleep when initially issued w/ first parents.   */
param<  INITIAL_SLEEP, initial_sleep, uns, 1>

/* awake state determined by the parent tags when op is still in map stage.  only useful when rat_time > 0. */
param<  PARENT_WAKE_MAP, parent_wake_map, uns, 1>

/* awake state determined by the parent tags when op is in node stage.  only useful when ops can sleep. */
param<  PARENT_WAKE_NODE, parent_wake_node, uns, 0>

/*base model. if parent is load , dont wake up on gp's.  set pipelined_schedule */
param<  LOAD_WAIT, load_wait, uns, 0>    /*base model */

/*if parent is load , dont wake up on gp's.  set pipelined_schedule */
param<  LOAD_LOW_PRIORITY, load_low_priority, uns, 0>    /*base model */

/*if parent is load , dont wake up on gp's.  set pipelined_schedule */
param<  WAKE_ON_SRC_LOAD, wake_on_src_load, uns, 0>    /*base model */

/*if parent is load , sleep extra cycles.  set pipelined_schedule */
param<  LOAD_SLEEP_EXTRA, load_sleep_extra, uns, 0>    /*base model */

/*if op has same src as last op in same slot, sleep extra cycles.  set pipelined_schedule */
param<  SAME_SRC_SLEEP_EXTRA, same_src_sleep_extra, uns, 0>    /*base model */

param<  SANITY_CHECK_PIPELINED, sanity_check_pipelined, uns, 0>    /*base model */

param<  READY_BLOCKED_STAT, ready_blocked_stat, uns, 0>    /*base model */

/* puts an n-cycle rfile access stage after the node stage 
   note: the collision handling (pipelined scheduling) techniques have  
   one cycle already built in due to the payload ram access.
*/
param<  RFILE_STAGE, 	       rfile_stage, int, 0>


/* for pipelined schedule, predict which parent will be ready last to wakeup on 2 gp's.
 * num counters is icache_size / 4.  
 * num counters per entry is icache_line_size / 4.
 * num entries is (icache_size / 4) / (icache_line_size / 4) = num icache lines.
 * direct-mapped, indexed by log(icache_size / 4) bits
 */
param<  PRED_LAST_SRC_RDY, pred_last_src_rdy, int, 0>
/* how many bits for each counter. */
param<  LSR_COUNTER_BITS, lsr_counter_bits, int, 2>
/* use a per-static instruction predictor rather than same size as cache. */
param<  LSR_PAP, lsr_pap, int, 0>
/* xor in n bits of branch history to table index (address).  for per-set predictor.  */
param<  LSR_BRANCH_HISTORY, lsr_branch_history, int, 0>

param<  SAMPLE_LOADS, sample_loads, int, 0>
param<  SAMPLER_RANDOM_BACKOFF, sampler_random_backoff, int, 0>
param<  SAMPLER_RANDOM_BACKOFF_AMT, sampler_random_backoff_amt, int, 8>
param<  DECODE_RANDOM_BACKOFF, decode_random_backoff, int, 0>
param<  DECODE_RANDOM_BACKOFF_AMT, decode_random_backoff_amt, int, 8>

param<  REDIR_LOAD_HASH_TABLE_SIZE, redir_load_hash_table_size, int, 8192>


     /*number of entries (addresses only for now) */
param<  REDIR_CACHE_SIZE, redir_cache_size, int, 257>
param<  ENABLE_REDIR_CACHE, enable_redir_cache, int, 1>


param<  REJECT_BACKOFF, reject_backoff, int, 2>
param<  EXTREME_REJECT_BACKOFF, extreme_reject_backoff, int, 40>
param<  BACKOFF_THRESHOLD, backoff_threshold, int, 3>

/* wait-time simple prediction table */
param<  ENABLE_WAIT_TIME_PREDICTION, enable_wait_time_prediction, int, 0>
param<  ENABLE_WAIT_TIME_CACHE, enable_wait_time_cache, int, 1>
param<  WAIT_TIME_TABLE_SIZE, wait_time_table_size, int, 4091>
param<  NEW_OPS_USE_DECODE_INFO, new_ops_use_decode_info, int, 0>

param<  STEERING_ALIGN_SIDE, steering_align_side, int, 0>

/* set if only load broadcast their tags.  */
param<  LOAD_BROADCAST, load_broadcast, int, 0>

param<  TRIGGER_SELECT_HEURISTIC, trigger_select_heuristic, int, 1>
/* 1: pick the closest load. */

param<  PRESCHEDULE_TRIGGER_SELECT, preschedule_trigger_select, int, 0>

param<  EXTRA_BROADCAST_DELAY, extra_broadcast_delay, int, 0>



     /* collision prediction parameters */
param<  PREVENT_COLLISION, prevent_collision, int, 0>
     /* 1: use a table of last-source-ready predictions to prevent multiple initial wakeups 
      * 2: uses even/odd cycle resource allocation, no resetting resource mask.
      * 6: 2 with a way to reset the resource mask.
      * 8: use source bit vector 
      * 16: use source bit vector in combination with pred_lsr
      * 32: use source bit vector, checked in node_stage rather than "code" vector
            (same mechanism as 1)
      * 64: use a (static, per-instruction) flag to indicate if there was a collision with previous
            op issued to same rs.  if flag is set, create an artificial dependency.
      * 128: steering by address lsbs

      * 2048: back_end predict collision (dep analysis, slot_assignment) (use 128)
      * 4096: front_end predict collision(dep analysis, slot_assignment) (use 128)
      * 8192: use the hash table.  don't use w/ 4096, 2, 64, 128, 256, 512, 1024, 
              use w/ 2048
      * 16384: use branch history for accessing table 
      * 32768: synchronize backend w/ frontend on redirects.
      * 65536: use slot assignment based on dependency chains.
     */

param<  SCHED_PREVENT_COLLISION, sched_prevent_collision, int, 0>
     /* set this if you are not using a collision prevention algorithm, but you want
	to use node_sched_prevent_collision.
     */
	    
param<  MAX_LOOKAHEAD_SCHED_ROWS, max_lookahead_sched_rows, int, 30>
     /* used for prevent_collision 2048 or 4096 */

param<  PC_TABLE_SIZE, pc_table_size, int, 2049>
param<  PC_TABLE_HISTORY_BITS, pc_table_history_bits, int, 2>
     /* how many bits of history used to index table */
param<  SYNCHRONIZATION_GAP, synchronization_gap, int, 1000>

param<  HANDLE_COLLISION, handle_collision, int, 0>
     /* 0: no penalty for collisions.  */
     /* 1: there is an collision_penalty-cycle penalty for the collisions. 
      *    this means the cycle 2 or more initially wake up is the 1st cycle of the penalty.
      * 2: if bit 1 is set, this means no ops can wakeup until the collision penalty is over
           with.  applies to multi-cycle penalties only.
	   if this bit is clear, this means ops can wakeup during this time, they just
	   can't be scheduled.  
      * 4: email to jared dated nov. 4
      * 12: 4 with this modification: each rs that did not have a collision can pick 
            something that woke up the cycle after last_collision_cycle (while colliding 
	    rss still in collision mode == 1), as long as the picked instructions sources
	    do not come from a colliding rs.  
      * 16: use in conjunction w/ 4.  when it goes into collision mode, redistribute
            the instructions across all functional units.  
      */

param<  COLLISION_PENALTY, collision_penalty, int, 1>


param<  MC_GLOBAL_SCHEDULING, mc_global_scheduling, int, 0>



param<  REPLAY_PENALTY, replay_penalty, int, 3>
param<  REPLAY_DETECT_CYCLES, replay_detect_cycles, int, 2>
     /* careful about this: replay_penalty - replay_detect_cycles = shadow. */
param<  NUM_WHB_ENTRIES, num_whb_entries, int, 8>
param<  WHB_ALLOC_DIST, whb_alloc_dist, int, 2, const)

param<  EN_DEP_CHAIN_STATS, en_dep_chain_stats, int, 0>

param<  RB_STEERING_ALGORITHM, rb_steering_algorithm, int, 1>
     // chang joo lee
param<  MARY_INSTRUCTION_SCHEDULE_MODEL, mary_instruction_schedule_model, bool, false>
